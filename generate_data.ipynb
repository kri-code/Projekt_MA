{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQtNJLWYbaKt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "!pip install spektral"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "-nlhama1bnKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################  get the whole training dataset\n",
        "\n",
        "#current_path = os.path.abspath('.')\n",
        "cortex_svz_cellcentroids = pd.read_csv(\"cortex_svz_cellcentroids.csv\")\n",
        "############# get batch adjacent matrix\n",
        "cell_view_list = []\n",
        "for view_num in range(7):\n",
        "    cell_view = cortex_svz_cellcentroids[cortex_svz_cellcentroids['Field of View']==view_num]\n",
        "    cell_view_list.append(cell_view)"
      ],
      "metadata": {
        "id": "7gngyp6FbrAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ the distribution of distance\n",
        "distance_list_list = []\n",
        "distance_list_list_2 = []\n",
        "print ('calculating distance matrix, it takes a while')\n",
        "for view_num in range(7):\n",
        "    print (view_num)\n",
        "    cell_view = cell_view_list[view_num]\n",
        "    distance_list = []\n",
        "    for j in range(cell_view.shape[0]):\n",
        "        for i in range (cell_view.shape[0]):\n",
        "            if i!=j:\n",
        "                distance_list.append(np.linalg.norm(cell_view.iloc[j][['X','Y']]-cell_view.iloc[i][['X','Y']]))\n",
        "    distance_list_list = distance_list_list + distance_list\n",
        "    distance_list_list_2.append(distance_list)\n",
        "\n",
        "\n",
        "# np.save(current_path+'/seqfish_plus/distance_array.npy',np.array(distance_list_list))"
      ],
      "metadata": {
        "id": "5OGVv5XCbtB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###try different distance threshold, so that on average, each cell has x neighbor cells, see Tab. S1 for results\n",
        "from scipy import sparse\n",
        "import spektral\n",
        "import pickle\n",
        "import scipy.linalg\n",
        "distance_array = np.array(distance_list_list)\n",
        "for threshold in [140]:#[100,140,180,210,220,260]:#range (210,211):#(100,400,40):\n",
        "    num_big = np.where(distance_array<threshold)[0].shape[0]\n",
        "    print (threshold,num_big,str(num_big/(913*2)))\n",
        "    distance_matrix_threshold_I_list = []\n",
        "    distance_matrix_threshold_W_list = []\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "    for view_num in range (7):\n",
        "        cell_view = cell_view_list[view_num]\n",
        "        distance_matrix = euclidean_distances(cell_view[['X','Y']], cell_view[['X','Y']])\n",
        "        distance_matrix_threshold_I = np.zeros(distance_matrix.shape)\n",
        "        distance_matrix_threshold_W = np.zeros(distance_matrix.shape)\n",
        "        for i in range(distance_matrix_threshold_I.shape[0]):\n",
        "            for j in range(distance_matrix_threshold_I.shape[1]):\n",
        "                if distance_matrix[i,j] <= threshold and distance_matrix[i,j] > 0:\n",
        "                    distance_matrix_threshold_I[i,j] = 1\n",
        "                    distance_matrix_threshold_W[i,j] = distance_matrix[i,j]\n",
        "        distance_matrix_threshold_I_list.append(distance_matrix_threshold_I)\n",
        "        distance_matrix_threshold_W_list.append(distance_matrix_threshold_W)\n",
        "    whole_distance_matrix_threshold_I = scipy.linalg.block_diag(distance_matrix_threshold_I_list[0],\n",
        "                                                                distance_matrix_threshold_I_list[1],\n",
        "                                                                distance_matrix_threshold_I_list[2],\n",
        "                                                                distance_matrix_threshold_I_list[3],\n",
        "                                                                distance_matrix_threshold_I_list[4],\n",
        "                                                                distance_matrix_threshold_I_list[5],\n",
        "                                                                distance_matrix_threshold_I_list[6])\n",
        "\n",
        "    '''\n",
        "    ############### get normalized sparse adjacent matrix\n",
        "    distance_matrix_threshold_I_N = spektral.utils.normalized_adjacency(whole_distance_matrix_threshold_I, symmetric=True)\n",
        "    print(type(distance_matrix_threshold_I_N))\n",
        "    distance_matrix_threshold_I_N_crs = sparse.csr_matrix(distance_matrix_threshold_I_N)\n",
        "    with open('whole_FOV_distance_I_N_norm_crs_'+str(threshold), 'wb') as fp:\n",
        "        pickle.dump(distance_matrix_threshold_I_N_crs, fp)'''\n",
        "    ############### get not normalized sparse adjacent matrix\n",
        "    distance_matrix_threshold_I_N = np.float32(whole_distance_matrix_threshold_I) ## do not normalize adjcent matrix\n",
        "    print(type(distance_matrix_threshold_I_N))\n",
        "    distance_matrix_threshold_I_N_crs = sparse.csr_matrix(distance_matrix_threshold_I_N)\n",
        "    with open('whole_FOV_distance_I_N_crs_'+str(threshold), 'wb') as fp:\n",
        "        pickle.dump(distance_matrix_threshold_I_N_crs, fp)"
      ],
      "metadata": {
        "id": "dwmKaPdibvaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########### read ligand receptor database\n",
        "ligand_list = pd.read_csv('ligand_list2.txt',header  = None)\n",
        "receptor_list = pd.read_csv('receptor_list2.txt',header  = None)\n",
        "LR_pairs = pd.read_csv('ligand_receptor_pairs2.txt',header  = None,sep ='\\t')"
      ],
      "metadata": {
        "id": "lGfiV1CHbyQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cortex_svz_counts = pd.read_csv(\"drive/MyDrive/cortex_svz_counts.csv\")\n",
        "cortex_svz_counts_N =cortex_svz_counts.div(cortex_svz_counts.sum(axis=1)+1, axis='rows')*10**4\n",
        "cortex_svz_counts_N.columns =[i.lower() for i in list(cortex_svz_counts_N)] ## gene expression normalization\n",
        "cortex_svz_cellcentroids = pd.read_csv('cortex_svz_cellcentroids.csv')\n",
        "# cortex_svz_counts_N_FOV = cortex_svz_counts_N"
      ],
      "metadata": {
        "id": "8n8JbU83b0Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gene_list =[i.lower() for i in list(cortex_svz_counts)]\n",
        "\n",
        "non_LR_list = [i for i in gene_list if i not in list(ligand_list.iloc[:,0]) and i not in list(receptor_list.iloc[:,0])]\n",
        "ovlp_ligand_list = [i for i in gene_list if i in list(ligand_list.iloc[:,0])]\n",
        "ovlp_receptor_list = [i for i in gene_list if i in list(receptor_list.iloc[:,0])]\n",
        "\n",
        "count = 0\n",
        "h_LR = defaultdict(list)\n",
        "for LR_pair_index in range(LR_pairs.shape[0]):\n",
        "    ligand, receptor =  LR_pairs.iloc[LR_pair_index]\n",
        "    if ligand in gene_list and receptor in gene_list:\n",
        "        h_LR[ligand].append(receptor)\n",
        "        count = count + 1"
      ],
      "metadata": {
        "id": "oJjBM9tEb2WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################### generate training dataset containing both postive and negative samples, where negative samples still in the ligand and receptor set, but not in pair set\n",
        "############################################# to split the LR database completely\n",
        "\n",
        "def generate_LR_pairs (h_LR_original,sub_ligand_list, sub_receptor_list,cortex_svz_counts_N):\n",
        "    h_LR = defaultdict(list)\n",
        "    for ligand in h_LR_original.keys():\n",
        "        if ligand in sub_ligand_list:\n",
        "            for receptor in h_LR_original[ligand]:\n",
        "                if receptor in sub_receptor_list:\n",
        "                    h_LR[ligand].append(receptor)\n",
        "    import random\n",
        "    random.seed(0)\n",
        "    count = 0\n",
        "    gene_pair_list  = []\n",
        "    X_data = []\n",
        "    Y_data = []\n",
        "    sub_ligand_list_ovlp = list(h_LR.keys())\n",
        "    for ligand in sub_ligand_list_ovlp:\n",
        "        for receptor in h_LR[ligand]:\n",
        "            gene_pair_list.append(ligand + '\\t' + receptor)\n",
        "            cell_LR_expression = np.array(cortex_svz_counts_N[[ligand, receptor]]) # postive sample\n",
        "            X_data.append(cell_LR_expression)\n",
        "            Y_data.append(1)\n",
        "            ############## get negative samples\n",
        "            non_pair_receptor_list = [i for i in sub_receptor_list if i not in h_LR[ligand]]\n",
        "            random.seed(count)\n",
        "            random_receptor = random.sample(non_pair_receptor_list, 1)[0]\n",
        "            gene_pair_list.append(ligand + '\\t' + random_receptor)\n",
        "            cell_LR_expression = np.array(cortex_svz_counts_N[[ligand, random_receptor]])\n",
        "            X_data.append(cell_LR_expression)\n",
        "            Y_data.append(0)\n",
        "            count = count + 1\n",
        "    ligand_record = sub_ligand_list_ovlp[0]\n",
        "    gene_pair_index = [0]\n",
        "    count = 0\n",
        "    for gene_pair in gene_pair_list:\n",
        "        ligand = gene_pair.split('\\t')[0]\n",
        "        if ligand == ligand_record:\n",
        "            count = count + 1\n",
        "        else:\n",
        "            gene_pair_index.append(count)\n",
        "            ligand_record = ligand\n",
        "            count = count + 1\n",
        "    gene_pair_index.append(count)\n",
        "    X_data_array = np.array(X_data)\n",
        "    Y_data_array = np.array(Y_data)\n",
        "    gene_pair_list_array = np.array(gene_pair_list)\n",
        "    gene_pair_index_array = np.array(gene_pair_index)\n",
        "    return (X_data_array,Y_data_array,gene_pair_list_array,gene_pair_index_array) ## x data, y data, gene pair name, index to separate pairs by ligand genes"
      ],
      "metadata": {
        "id": "uaAtU-7hb3-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## ten fold cross validation data generation\n",
        "ovlp_ligand_list_cons = ovlp_ligand_list\n",
        "ovlp_receptor_list_cons = ovlp_receptor_list\n",
        "import random\n",
        "random.seed(1)\n",
        "ovlp_ligand_list = random.sample(ovlp_ligand_list_cons,len(ovlp_ligand_list))\n",
        "random.seed(1)\n",
        "ovlp_receptor_list = random.sample(ovlp_receptor_list_cons,len(ovlp_receptor_list))\n",
        "for test_indel in range(1,11): ################## ten fold cross validation\n",
        "    print (test_indel)\n",
        "    ######### completely separate ligand and recpetor genes as mutually  exclusive train and test set\n",
        "    whole_ligand_index = [i for i in range(len(ovlp_ligand_list))]\n",
        "    test_ligand = [i for i in range (int(np.ceil((test_indel-1)*0.1*len(ovlp_ligand_list))),int(np.ceil(test_indel*0.1*len(ovlp_ligand_list))))]\n",
        "    train_ligand= [i for i in whole_ligand_index if i not in test_ligand]\n",
        "    whole_receptor_index = [i for i in range(len(ovlp_receptor_list))]\n",
        "    test_receptor = [i for i in range(int(np.ceil((test_indel - 1) * 0.1 * len(ovlp_receptor_list))),int(np.ceil(test_indel * 0.1 * len(ovlp_receptor_list))))]\n",
        "    train_receptor = [i for i in whole_receptor_index if i not in test_receptor]\n",
        "    X_data_array_train, Y_data_array_train, gene_pair_list_array_train, gene_pair_index_array_train = generate_LR_pairs (h_LR,np.array(ovlp_ligand_list)[train_ligand], np.array(ovlp_receptor_list)[train_receptor],cortex_svz_counts_N)\n",
        "    X_data_array_test, Y_data_array_test, gene_pair_list_array_test, gene_pair_index_array_test = generate_LR_pairs(h_LR, np.array(ovlp_ligand_list)[test_ligand], np.array(ovlp_receptor_list)[test_receptor], cortex_svz_counts_N)\n",
        "\n",
        "    if not os.path.isdir('rand_1_10fold/'):\n",
        "        os.makedirs( 'rand_1_10fold/')\n",
        "    np.save('rand_1_10fold/'+str(test_indel)+'_train_X_data_array.npy', X_data_array_train)\n",
        "    np.save('rand_1_10fold/'+str(test_indel)+'_train_Y_data_array.npy', Y_data_array_train)\n",
        "    np.save('rand_1_10fold/'+str(test_indel)+'_train_gene_pair_list_array.npy', gene_pair_list_array_train)\n",
        "    np.save('rand_1_10fold/'+str(test_indel)+'_train_gene_pair_index_array.npy', gene_pair_index_array_train)\n",
        "    np.save('rand_1_10fold/' + str(test_indel) + '_test_X_data_array.npy',X_data_array_test)\n",
        "    np.save('rand_1_10fold/' + str(test_indel) + '_test_Y_data_array.npy',Y_data_array_test)\n",
        "    np.save('rand_1_10fold/' + str(test_indel) + '_test_gene_pair_list_array.npy',gene_pair_list_array_test)\n",
        "    np.save('rand_1_10fold/' + str(test_indel) + '_test_gene_pair_index_array.npy',gene_pair_index_array_test)"
      ],
      "metadata": {
        "id": "h1Nc1Fi5b7GD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}