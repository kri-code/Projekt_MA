{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "hlnNSGSZHvoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "Mogry3IuTZr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "VUBQu_Gr_sa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8tR_h9Qf92-",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f3fd49-c35b-4188-8944-6d77025137ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_scatter-2.1.2%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_scatter-2.1.2%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt22cu121\n",
            "Successfully installed torch-scatter-2.1.2+pt22cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
            "Collecting torch-sparse\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_sparse-0.6.18%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_sparse-0.6.18%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt22cu121\n",
            "Successfully installed torch-sparse-0.6.18+pt22cu121\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-39ufzopu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-39ufzopu\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-39ufzopu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-39ufzopu\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 5034fef0567f7a095b973a58b508ea2d59d3b5ce\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 5034fef0567f7a095b973a58b508ea2d59d3b5ce\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.10.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (4.0.3)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.10.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.7.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric==2.7.0) (4.12.2)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.7.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric==2.7.0) (4.12.2)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1136511 sha256=cbfacfd1df19abcc3c66784297c5f957fc18bac7e42ede5e25cc77870eb2157c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9amixeky/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1136511 sha256=cbfacfd1df19abcc3c66784297c5f957fc18bac7e42ede5e25cc77870eb2157c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9amixeky/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.2.1+cu121.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "ohKWzmq9gTvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmxvU8hsgWAU",
        "outputId": "eda90c82-b59c-4ee4-cadb-f093097f3863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAIN**\n",
        "\n",
        "with PyG (PyTorch Geometric) library\n",
        "# autocrine+ GCNG that uses both exocrine and autocrine gene interactions\n",
        "#For diagonal GCNG, just feed it with a zero matrix instead of adjacent matrix."
      ],
      "metadata": {
        "id": "4-1B23ksCcZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from numpy import interp"
      ],
      "metadata": {
        "id": "JNFe97X6CgQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "import numpy as np\n",
        "from scipy import sparse as sp\n",
        "import pickle\n",
        "threshold = 140\n",
        "with open('whole_FOV_distance_I_N_norm_crs_140_norm_lap', 'rb') as fp:\n",
        "    adj = pickle.load( fp)\n",
        "#with open('whole_FOV_distance_I_N_crs_140', 'rb') as fp:\n",
        "    #adj = pickle.load( fp)"
      ],
      "metadata": {
        "id": "EIyCZ1FMC26V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def degree_power(adj, pow):\n",
        "    \"\"\"\n",
        "    Computes \\(D^{p}\\) from the given adjacency matrix. Useful for computing\n",
        "    normalised Laplacians.\n",
        "    :param adj: rank 2 array or sparse matrix\n",
        "    :param pow: exponent to which elevate the degree matrix\n",
        "    :return: the exponentiated degree matrix in sparse DIA format\n",
        "    \"\"\"\n",
        "    degrees = np.power(np.array(adj.sum(1)), pow).flatten()\n",
        "    degrees[np.isinf(degrees)] = 0.\n",
        "    if sp.issparse(adj):\n",
        "        D = sp.diags(degrees)\n",
        "    else:\n",
        "        D = np.diag(degrees)\n",
        "    return D\n",
        "\n",
        "\n",
        "def self_connection_normalized_adjacency(adj, symmetric=True):\n",
        "    \"\"\"\n",
        "    Normalizes the given adjacency matrix using the degree matrix as either\n",
        "    \\(D~^{-1}A~\\) or \\(D~^{-1/2}A~D~^{-1/2}\\) (symmetric normalization).where A~ = A+I\n",
        "    :param adj: rank 2 array or sparse matrix;\n",
        "    :param symmetric: boolean, compute symmetric normalization;\n",
        "    :return: the normalized adjacency matrix.\n",
        "    \"\"\"\n",
        "    if sp.issparse(adj):\n",
        "        I = sp.eye(adj.shape[-1], dtype=adj.dtype)\n",
        "    else:\n",
        "        I = np.eye(adj.shape[-1], dtype=adj.dtype)\n",
        "    A1 = adj + I\n",
        "    if symmetric:\n",
        "        normalized_D = degree_power(A1, -0.5)\n",
        "        output = normalized_D.dot(A1).dot(normalized_D)\n",
        "    else:\n",
        "        normalized_D = degree_power(A1, -1.)\n",
        "        output = normalized_D.dot(A1)\n",
        "    return output\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "w3G1Q6OyC8v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MATRIX"
      ],
      "metadata": {
        "id": "IaP9aPPvXptj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import  csr_matrix, coo_matrix\n",
        "from torch_geometric.utils import to_edge_index, get_laplacian"
      ],
      "metadata": {
        "id": "cJRqSMv-keCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f8318a-d002-4573-97d1-69c91e6ec778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR EXOCRINE INTERACTION**"
      ],
      "metadata": {
        "id": "2uimzfeiU0MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fltr_tensor = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "fltr_tensor = fltr_tensor.to_sparse_csr() # transform to csr format\n",
        "edge_index, edge_weight = to_edge_index(fltr_tensor) #edge index  & edge weight\n",
        "print(edge_weight)\n",
        "\n",
        "edge_weight = edge_weight.abs()\n",
        "print(edge_index.shape)\n",
        "print(edge_weight)\n"
      ],
      "metadata": {
        "id": "Yx_ApgYNU8qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07d40e6-42ca-46e9-b00e-6665ca4320aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.0000, -1.0000,  1.0000,  ..., -0.4711, -0.2721,  1.0000])\n",
            "torch.Size([2, 5396])\n",
            "tensor([1.0000, 1.0000, 1.0000,  ..., 0.4711, 0.2721, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR AUTOCRINE INTERACTION**"
      ],
      "metadata": {
        "id": "sr9lpuQiVJ-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = (913,913)\n",
        "adj_z = np.zeros(s)\n",
        "fltr = self_connection_normalized_adjacency(adj_z)\n",
        "f = torch.from_numpy(fltr).to_sparse()\n",
        "f = f.to_sparse_csr()\n",
        "edge_index, edge_weight = to_edge_index(f) #edge index (2,913) & edge weight (913)\n",
        "edge_weight = torch.ones(913)\n",
        "print(edge_weight)\n",
        "\n"
      ],
      "metadata": {
        "id": "DOFnVhqQ5xXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7478c71a-ef88-4094-ede7-4449611bd3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-ee4095c0635f>:5: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  f = f.to_sparse_csr()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR AUTOCRINE AND EXOCRINE INTERACTION**"
      ],
      "metadata": {
        "id": "qOV_xXdCVR8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in case of autocrine+\n",
        "fltr = self_connection_normalized_adjacency(adj)\n",
        "\n",
        "fltr_tensor = sparse_mx_to_torch_sparse_tensor(fltr) # adj to tensor (coo format)\n",
        "\n",
        "fltr_tensor = fltr_tensor.to_sparse_csr() # transform to csr format\n",
        "edge_index, edge_weight = to_edge_index(fltr_tensor) #edge index (2,5403) & edge weight (5403)\n"
      ],
      "metadata": {
        "id": "1wsA_jsSXmwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0bd276-c9df-449e-d2e4-042094ab8909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2df613f4e512>:46: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:641.)\n",
            "  return torch.sparse.FloatTensor(indices, values, shape)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv, GraphConv, GATConv,GATv2Conv, global_mean_pool, global_max_pool\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "IugHEJLXE2xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval"
      ],
      "metadata": {
        "id": "CtdlUkwpoit-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284a5117-d738-4bd9-aec1-561628faa4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torcheval.metrics import BinaryAccuracy, BinaryAUROC"
      ],
      "metadata": {
        "id": "OI3-5B9HoygS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "l2_reg = 5e-7  # Regularization rate for l2\n",
        "learning_rate = 1*1e-6  # Learning rate for SGD\n",
        "batch_size = 16  # Batch size\n",
        "epochs = 10 # Number of training epochs\n",
        "es_patience = 5  # Patience fot early stopping\n",
        "criterion = torch.nn.BCELoss()\n",
        "pool_batch = torch.zeros(913, dtype=int)\n"
      ],
      "metadata": {
        "id": "t00ULJg0O8_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition 1\n",
        "# Epochs: 30\n",
        "# batch size: 32\n",
        "class GCN(torch.nn.Module):\n",
        "      def __init__(self, matrix, weight):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(1234567)\n",
        "        self.adj = matrix\n",
        "        self.weight = weight\n",
        "        self.conv1 = GCNConv(in_channels=2, out_channels=32, add_self_loops=False, bias=True)\n",
        "        self.conv2 = GCNConv(in_channels= 32, out_channels=32, add_self_loops=False, bias=True)\n",
        "        self.linear1 = torch.nn.Linear(29216,512) #29216\n",
        "        self.linear2 = torch.nn.Linear(512,1)\n",
        "        self.activation = torch.nn.ELU()\n",
        "\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "        #print(\"X:\", x.shape, \"Adj:\", adj)\n",
        "        x = self.conv1(x, self.adj, edge_weight = self.weight)\n",
        "        x = self.activation(x)\n",
        "        #x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, self.adj, edge_weight =self.weight)\n",
        "        x = self.activation(x)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.linear1(x)\n",
        "        x = x.relu()\n",
        "        x = self.linear2(x)\n",
        "        x = x.sigmoid()\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "NGHZYWCAOjS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition 2\n",
        "# Epochs: 30\n",
        "# batch size: 32\n",
        "class GCN(torch.nn.Module):\n",
        "      def __init__(self, matrix, weight):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(1234567)\n",
        "        self.adj = matrix\n",
        "        self.weight = weight\n",
        "        self.conv1 = GCNConv(in_channels=2, out_channels=32, add_self_loops=False, bias=True)\n",
        "        self.conv2 = GCNConv(in_channels= 32, out_channels=32, add_self_loops=False, bias=True)\n",
        "        #self.linear1 = torch.nn.Linear(29216,512) #29216\n",
        "        self.linear1 = torch.nn.Linear(32,16)\n",
        "        self.linear3 = torch.nn.Linear(32,32)\n",
        "        self.linear2 = torch.nn.Linear(16,1)\n",
        "        self.activation = torch.nn.ELU()\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "        #print(\"X:\", x.shape, \"Adj:\", adj)\n",
        "        x = self.conv1(x, self.adj, edge_weight = self.weight)\n",
        "        x = self.activation(x)\n",
        "        #x = self.dropout(x)\n",
        "        x = self.conv2(x, self.adj, edge_weight = self.weight)\n",
        "        x = self.activation(x)\n",
        "        #x = self.dropout(x)\n",
        "        x = self.conv2(x, self.adj, edge_weight =self.weight)\n",
        "        #x = global_mean_pool(x, pool_batch)\n",
        "        x = self.activation(x)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        #x = self.linear3(x)\n",
        "        #x = x.relu()\n",
        "        #x = self.dropout(x)\n",
        "        x = self.linear1(x)\n",
        "        x = x.relu()\n",
        "        #x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        x = x.sigmoid()\n",
        "        return x"
      ],
      "metadata": {
        "id": "z40xhlb5e-ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition 3\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        torch.manual_seed(12345678978)\n",
        "        self.conv1 = GATConv(in_channels=2, out_channels=3, heads=5, add_self_loops=False ,dropout=0)\n",
        "        self.conv2 = GATConv(in_channels=15,out_channels=3, add_self_loops=False, concat=False, heads=1, dropout=0)\n",
        "        self.activation = torch.nn.ELU()\n",
        "        self.dropout = torch.nn.Dropout(p=0.6)\n",
        "        self.linear1 = torch.nn.Linear(2739,512) #2739\n",
        "        self.linear2 = torch.nn.Linear(512,1)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        #x, edge_index, z = data[0], data[1], data[2]\n",
        "        x = self.conv1(x, edge_index)\n",
        "\n",
        "        x = self.activation(x)\n",
        "        #x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        x = x.flatten()\n",
        "\n",
        "\n",
        "        x = self.linear1(x)\n",
        "        x = x.relu()\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        x = x.sigmoid()\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "zsdXE8vuMemN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition TEST\n",
        "# Epochs: 10\n",
        "# batch size: 16\n",
        "class GCN(torch.nn.Module):\n",
        "      def __init__(self, matrix, weight):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(1234567)\n",
        "        self.adj = matrix\n",
        "        self.weight = weight\n",
        "        self.conv1 = GraphConv(in_channels=2, out_channels=8, bias=True)\n",
        "        self.conv2 = GraphConv(in_channels= 8, out_channels=8, bias=True)\n",
        "        self.linear1 = torch.nn.Linear(7304,512) #29216\n",
        "        self.linear2 = torch.nn.Linear(512,1)\n",
        "        self.activation = torch.nn.ELU()\n",
        "\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "        #print(\"X:\", x.shape, \"Adj:\", adj)\n",
        "        x = self.conv1(x, self.adj, edge_weight = self.weight)\n",
        "        x = self.activation(x)\n",
        "        #x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, self.adj, edge_weight =self.weight)\n",
        "        x = self.activation(x)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.linear1(x)\n",
        "        x = x.relu()\n",
        "        x = self.linear2(x)\n",
        "        x = x.sigmoid()\n",
        "        return x"
      ],
      "metadata": {
        "id": "bKGrxHbveFBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "sgmp8RVU4Ki_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data\n"
      ],
      "metadata": {
        "id": "mugUBWbYn_dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data_utils"
      ],
      "metadata": {
        "id": "Ln5TGlTiRldr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve,auc, precision_recall_curve"
      ],
      "metadata": {
        "id": "fOmzf4EteHod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "4ObXP45X_nAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_concatenation(matrix):\n",
        "     flat_list = []\n",
        "     for row in matrix:\n",
        "         flat_list += row\n",
        "     return flat_list\n",
        "\n",
        "def ligand_name(pairs):\n",
        "  pairs = list(pairs)\n",
        "  o =[]\n",
        "  for item in pairs:\n",
        "    if \"\\\\\" in r\"%r\" % item:\n",
        "      break\n",
        "    else:\n",
        "      o.append(item)\n",
        "  fin = \"\".join(o)\n",
        "  return fin"
      ],
      "metadata": {
        "id": "N_-5KAiPxfdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader):\n",
        "      out_list = []\n",
        "      loss_list = []\n",
        "      model.train()\n",
        "      for data, label in train_loader:  # Iterate in batches over the training dataset.\n",
        "        optimizer.zero_grad()  # Clear gradients.\n",
        "        out = model(data) # Perform a single forward pass.\n",
        "        out_list.append(out)\n",
        "        loss = criterion(out, label) # Compute the loss.\n",
        "        loss_list.append(loss.item())\n",
        "        loss.backward() # Derive gradients.\n",
        "        optimizer.step() # Update parameters based on gradients.\n",
        "      return out_list, loss_list\n",
        "\n",
        "def train_GAT(trainloader, adj):\n",
        "      out_list = []\n",
        "      loss_list = []\n",
        "      model.train()\n",
        "      for data, label in trainloader:  # Iterate in batches over the training dataset.\n",
        "        # for GAT because static graph not supported\n",
        "        #print(edge_index)\n",
        "        adj_result = [adj] * len(data)\n",
        "\n",
        "        te = [Data(x_train=x, edge_index=a) for x,a in zip(data, adj_result)]\n",
        "\n",
        "        batch = Batch.from_data_list(te)\n",
        "        #batch = batch.to(device)\n",
        "\n",
        "        #train_loader = data_utils.DataLoader(t, batch_size=batch_size, shuffle=False)\n",
        "        optimizer.zero_grad()  # Clear gradients.\n",
        "        out = model(batch.x_train, batch.edge_index, len(data)) # Perform a single forward pass.\n",
        "        out_list.append(out)\n",
        "\n",
        "        loss = criterion(out, label.flatten()) # Compute the loss.\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        loss.backward() # Derive gradients.\n",
        "        optimizer.step() # Update parameters based on gradients.\n",
        "      return out_list, loss_list\n",
        "\n",
        "\n",
        "\n",
        "def test(test_loader):\n",
        "     model.eval()\n",
        "\n",
        "     out_list = []\n",
        "     for data in test_loader:  # Iterate in batches over the test dataset.\n",
        "         out = model(data)\n",
        "         out_list.append(out)\n",
        "\n",
        "     return out_list\n",
        "\n",
        "def test_GAT(test_loader, adj):\n",
        "     model.eval()\n",
        "\n",
        "     out_list = []\n",
        "     for data in test_loader:  # Iterate in batches over the test dataset.\n",
        "         adj_result = [adj] * len(data)\n",
        "\n",
        "         te = [Data(x_train=x, edge_index=a) for x,a in zip(data, adj_result)]\n",
        "\n",
        "         batch = Batch.from_data_list(te)\n",
        "         out = model(batch.x_train, batch.edge_index, len(data))\n",
        "         out_list.append(out)\n",
        "\n",
        "     return out_list\n"
      ],
      "metadata": {
        "id": "aIMCtw_Df1ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data, Batch, DataLoader"
      ],
      "metadata": {
        "id": "BUKWckh4U9eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1],[2],[3]])\n",
        "b = np.array([[61],[72],[83]])\n",
        "f = np.append(a,b,axis=0)\n",
        "print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvJqUG7YK9SU",
        "outputId": "00d6f1ce-c13d-4fd3-86cc-154a269d0640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [61]\n",
            " [72]\n",
            " [83]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_accuracy_train = []\n",
        "total_accuracy_train_final = []\n",
        "total_accuracy_test_final = []\n",
        "tn_total = []\n",
        "fp_total = []\n",
        "fn_total = []\n",
        "tp_total = []\n",
        "tprs = []\n",
        "aucs = []\n",
        "w = 1\n",
        "mean_fpr = np.linspace(0,1,100)\n",
        "for test_indel in range(1,11): ################## ten fold cross validation\n",
        "    print(\"FOLD\", test_indel)\n",
        "    print(\"----------------------------------------------------------\")\n",
        "    X_data_train = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_train_X_data_array.npy')\n",
        "    Y_data_train = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_train_Y_data_array.npy')\n",
        "    gene_pair_index_train = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_train_gene_pair_list_array.npy')\n",
        "    count_setx_train = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_train_gene_pair_index_array.npy')\n",
        "    X_data_test = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_test_X_data_array.npy')\n",
        "    Y_data_test = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_test_Y_data_array.npy')\n",
        "    gene_pair_index_test = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_test_gene_pair_list_array.npy')\n",
        "    count_set = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_test_gene_pair_index_array.npy')\n",
        "    trainX_index = [i for i in range(Y_data_train.shape[0])]\n",
        "    validation_index = trainX_index[:int(np.ceil(0.2*len(trainX_index)))]\n",
        "    train_index = trainX_index[int(np.ceil(0.2*len(trainX_index))):]\n",
        "    X_train, y_train = X_data_train[train_index],Y_data_train[train_index][:,np.newaxis]\n",
        "    X_val, y_val= X_data_train[validation_index],Y_data_train[validation_index][:,np.newaxis]\n",
        "    X_test, y_test= X_data_test,Y_data_test[:,np.newaxis]\n",
        "\n",
        "    # X_train, y_train, X_val, y_val, X_test, y_test, adj = mnist.load_data()\n",
        "    # X_train, X_val, X_test = X_train[..., None], X_val[..., None], X_test[..., None]\n",
        "    N = X_train.shape[-2]  # Number of nodes in the graphs\n",
        "    F = X_train.shape[-1]  # Node features dimensionality\n",
        "    n_out = y_train.shape[-1]  # Dimension of the target\n",
        "\n",
        "    ############################################\n",
        "    #for further training without validation\n",
        "\n",
        "    X_train = np.append(X_train,X_val,axis=0)\n",
        "\n",
        "    y_train = np.append(y_train,y_val,axis=0)\n",
        "    ############################################\n",
        "\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "    X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "    y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    dataset = data_utils.TensorDataset(X_train, y_train)\n",
        "    val_dataset = data_utils.TensorDataset(X_val, y_val)\n",
        "\n",
        "\n",
        "    train_loader = data_utils.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = data_utils.DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
        "    validation_loader = data_utils.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model = GCN(edge_index, edge_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
        "\n",
        "    all_losses = []\n",
        "\n",
        "    #Initialize Variables for EarlyStopping\n",
        "    best_loss = float('inf')\n",
        "    best_model_weights = None\n",
        "    patience = 5\n",
        "    t = open('training/'+str(test_indel)+'results.txt', 'w')\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      print(\"Starting Epoch\", epoch)\n",
        "      accuracy_train_list = []\n",
        "      output, loss = train(train_loader)\n",
        "\n",
        "      total_loss = sum(loss) / len(loss)\n",
        "\n",
        "\n",
        "      # Validation\n",
        "      #model.eval()  # Set model to evaluation mode\n",
        "      #with torch.no_grad():  # Disable gradient calculation for validation\n",
        "          #val_loss_list = []\n",
        "          #for val_data, val_label in validation_loader:\n",
        "            #val_outputs = model(val_data)\n",
        "            #val_loss = criterion(val_outputs, val_label)\n",
        "            #val_loss_list.append(val_loss)\n",
        "\n",
        "      #val_loss = sum(val_loss_list) / len(val_loss_list)\n",
        "      # Early stopping\n",
        "      #if val_loss < best_loss:\n",
        "          #best_loss = val_loss\n",
        "          #best_model_weights = copy.deepcopy(model.state_dict())  # Deep copy here\n",
        "          #patience = patience  # Reset patience counter\n",
        "      #else:\n",
        "          #patience -= 1\n",
        "          #if patience == 0:\n",
        "              #break\n",
        "\n",
        "\n",
        "      best_model_weights = copy.deepcopy(model.state_dict())  # Deep copy here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # training accuracy, threshold 0.5\n",
        "      final_out = []\n",
        "      for out in output:\n",
        "        output_train_acc = out\n",
        "        output_train_acc[output_train_acc >= 0.5] = 1\n",
        "        output_train_acc[output_train_acc < 0.5] = 0\n",
        "        #output_train_acc_int = int(output_train_acc)   # float to int\n",
        "        output_train_acc_int = output_train_acc.tolist()\n",
        "        output_train_acc_int = flatten_concatenation(output_train_acc_int)\n",
        "        output_train_acc_int = [ int(x) for x in output_train_acc_int ]\n",
        "        final_out.append(output_train_acc_int)\n",
        "\n",
        "      final_output = flatten_concatenation(final_out)\n",
        "\n",
        "\n",
        "      all_losses.append(total_loss)\n",
        "\n",
        "      accuracy_train = accuracy_score(y_train.flatten(), final_output)\n",
        "      total_accuracy_train.append(accuracy_train)\n",
        "      print(f'Epoch: {epoch:03d}, Loss: {total_loss:.4f}, Accuracy: {accuracy_train:.4f}')\n",
        "      val_loss = 0\n",
        "\n",
        "      t.write(\"FOLD\" + '\\t' + str(test_indel) + '\\t' + \"EPOCH\" + '\\t' + str(epoch) +\"LOSS\" + \"\\t\"+str(total_loss) + \"\\t\"+ \"VALIDATION LOSS\" + \"\\t\"+str(val_loss) +'\\t' + \"TRAINING ACCURACY\" + '\\t'+ str(accuracy_train) + '\\n')\n",
        "\n",
        "\n",
        "\n",
        "    t.close()\n",
        "\n",
        "    overall_loss = sum(all_losses) / epochs\n",
        "    print(f'OVERALL LOSS EPOCH: {overall_loss:.4f}')\n",
        "    sum_train_acc = sum(total_accuracy_train) / epochs\n",
        "    total_accuracy_train = []\n",
        "    total_accuracy_train_final.append(sum_train_acc)\n",
        "\n",
        "    # Load the best model weights\n",
        "    model.load_state_dict(best_model_weights)\n",
        "\n",
        "    #############################################\n",
        "    #              TEST                         #\n",
        "    #############################################\n",
        "\n",
        "    print(\"FOLD\", test_indel, \"TESTING\")\n",
        "\n",
        "    test_output = test(test_loader)\n",
        "    final_out = []\n",
        "    for out in test_output:\n",
        "      output_test_acc = out\n",
        "      output_test_acc[output_test_acc >= 0.5] = 1\n",
        "      output_test_acc[output_test_acc < 0.5] = 0\n",
        "      #output_train_acc_int = int(output_train_acc)   # float to int\n",
        "      output_test_acc_int = output_test_acc.tolist()\n",
        "      output_test_acc_int = flatten_concatenation(output_test_acc_int)\n",
        "      output_test_acc_int = [ int(x) for x in output_test_acc_int ]\n",
        "      final_out.append(output_test_acc_int)\n",
        "\n",
        "    final_output = flatten_concatenation(final_out)\n",
        "\n",
        "    #Accuracy\n",
        "    accuracy_test = accuracy_score(y_test.flatten(), final_output)\n",
        "    total_accuracy_test_final.append(accuracy_test)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test.flatten(), final_output)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    tn_total.append(tn)\n",
        "    fp_total.append(fp)\n",
        "    fn_total.append(fn)\n",
        "    tp_total.append(tp)\n",
        "\n",
        "\n",
        "    y_testy = y_test.flatten()\n",
        "    y_predicty = final_output\n",
        "    s = open('result/'+str(test_indel)+'divided_interaction.txt', 'w')\n",
        "    for jj in range(len(count_set) - 1):  # len(count_set)-1):\n",
        "        if count_set[jj] < count_set[jj + 1]:\n",
        "            y_test_1 = y_testy[count_set[jj]:count_set[jj + 1]]\n",
        "            y_predict = y_predicty[count_set[jj]:count_set[jj + 1]]\n",
        "            # Score trained model.\n",
        "            cm_1 = confusion_matrix(y_test_1, y_predict)\n",
        "            tn_1, fp_1, fn_1, tp_1 = cm_1.ravel()\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(y_test_1, y_predict, pos_label=1)\n",
        "            auc = metrics.auc(fpr, tpr)\n",
        "            li_name = ligand_name(gene_pair_index_test[count_set[jj]])\n",
        "            s.write(li_name + '\\n')\n",
        "            s.write(str(jj) + '\\t' + str(count_set[jj]) + '\\t' + str(count_set[jj + 1]) + '\\t' + str(auc) + '\\n')\n",
        "            s.write(str(jj) + '\\t' + str(count_set[jj]) + '\\t' + str(count_set[jj + 1]) + '\\t' + \"TN\" + str(tn_1) + \"FP\" + str(fp_1) + \"FN\" + str(fn_1) + \"TP\"+ str(tp_1) + '\\n')\n",
        "\n",
        "    s.close()\n",
        "\n",
        "    print(\"FOLD\", test_indel, \"Test Accuracy:\", accuracy_test)\n",
        "    print(\"FOLD\", test_indel,\"Confusion Matrix:\", cm)\n",
        "\n",
        "    fpr, tpr, t = roc_curve(y_test.flatten(), final_output)\n",
        "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    aucs.append(roc_auc)\n",
        "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (w, roc_auc))\n",
        "    w = w+1\n",
        "\n",
        "\n",
        "    precision1, recall1, thresholds1 = precision_recall_curve(y_test.flatten(), final_output)\n",
        "    auc_score_rp = metrics.auc(recall1, precision1)\n",
        "    print(\"FOLD\", test_indel,\"AREA UNDER ROC CURVE:\", roc_auc)\n",
        "    print(\"FOLD\", test_indel,\"AREA UNDER P-R CURVE:\", auc_score_rp)\n",
        "    e = open('ending/'+str(test_indel)+'curves.txt', 'w')\n",
        "    e.write(\"FOLD\" + \"\\t\"+  str(test_indel)+ \"\\t\"+ \"TEST ACCURACY:\" + \"\\t\"+ str(accuracy_test) + '\\n')\n",
        "    e.write(\"FOLD\" + \"\\t\"+  str(test_indel)+ \"\\t\"+ \"TEST CONFUSION MATRIX:\" + \"\\t\"+ str(cm) + '\\n')\n",
        "    e.write(\"FOLD\" + \"\\t\"+  str(test_indel)+ \"\\t\"+ \"AREA UNDER ROC CURVE:\" + \"\\t\"+ str(roc_auc) + '\\n')\n",
        "    e.write(\"FOLD\" + \"\\t\"+  str(test_indel)+ \"\\t\"+ \"AREA UNDER P-R CURVE:\" + \"\\t\"+ str(auc_score_rp) + '\\n')\n",
        "    e.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"10 FOLD CROSS VALIDATION RESULT\")\n",
        "print(\"--------------------------------------------------------------\")\n",
        "avg_accuracy_train = sum(total_accuracy_train_final) / 10\n",
        "avg_accuracy_test = sum(total_accuracy_test_final) / 10\n",
        "print(\"Average Training Accuracy\", avg_accuracy_train)\n",
        "print(\"Average Testing Accuracy\", avg_accuracy_test)\n",
        "print(\"True Negative:\", sum(tn_total), \"False Positive:\", sum(fp_total), \"False Negative:\", sum(fn_total), \"True Positive:\", sum(tp_total))\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
        "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
        "         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
        "plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7RZ0NOMHDEkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158f162f-503e-47b1-b5f3-9dbe0f682e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 1\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6945, Accuracy: 0.4912\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6924, Accuracy: 0.5243\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6907, Accuracy: 0.5427\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6891, Accuracy: 0.5625\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6876, Accuracy: 0.5836\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6861, Accuracy: 0.6034\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6847, Accuracy: 0.6175\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6833, Accuracy: 0.6288\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6820, Accuracy: 0.6387\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6807, Accuracy: 0.6450\n",
            "OVERALL LOSS EPOCH: 0.6871\n",
            "FOLD 1 TESTING\n",
            "FOLD 1 Test Accuracy: 0.6\n",
            "FOLD 1 Confusion Matrix: [[2 3]\n",
            " [1 4]]\n",
            "FOLD 1 AREA UNDER ROC CURVE: 0.6000000000000001\n",
            "FOLD 1 AREA UNDER P-R CURVE: 0.7357142857142857\n",
            "FOLD 2\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6941, Accuracy: 0.4960\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6918, Accuracy: 0.5316\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6901, Accuracy: 0.5541\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6885, Accuracy: 0.5744\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6870, Accuracy: 0.5926\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6855, Accuracy: 0.6071\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6841, Accuracy: 0.6115\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6827, Accuracy: 0.6180\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6814, Accuracy: 0.6275\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6800, Accuracy: 0.6354\n",
            "OVERALL LOSS EPOCH: 0.6865\n",
            "FOLD 2 TESTING\n",
            "FOLD 2 Test Accuracy: 0.55\n",
            "FOLD 2 Confusion Matrix: [[9 1]\n",
            " [8 2]]\n",
            "FOLD 2 AREA UNDER ROC CURVE: 0.55\n",
            "FOLD 2 AREA UNDER P-R CURVE: 0.6333333333333333\n",
            "FOLD 3\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6938, Accuracy: 0.4918\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6916, Accuracy: 0.5374\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6896, Accuracy: 0.5567\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6879, Accuracy: 0.5873\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6862, Accuracy: 0.6058\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6846, Accuracy: 0.6222\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6831, Accuracy: 0.6379\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6816, Accuracy: 0.6443\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6801, Accuracy: 0.6500\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6786, Accuracy: 0.6500\n",
            "OVERALL LOSS EPOCH: 0.6857\n",
            "FOLD 3 TESTING\n",
            "FOLD 3 Test Accuracy: 0.3888888888888889\n",
            "FOLD 3 Confusion Matrix: [[5 4]\n",
            " [7 2]]\n",
            "FOLD 3 AREA UNDER ROC CURVE: 0.38888888888888895\n",
            "FOLD 3 AREA UNDER P-R CURVE: 0.4722222222222222\n",
            "FOLD 4\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6938, Accuracy: 0.4964\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6917, Accuracy: 0.5360\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6899, Accuracy: 0.5677\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6881, Accuracy: 0.5893\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6865, Accuracy: 0.6016\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6849, Accuracy: 0.6167\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6834, Accuracy: 0.6326\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6818, Accuracy: 0.6463\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6803, Accuracy: 0.6542\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6788, Accuracy: 0.6621\n",
            "OVERALL LOSS EPOCH: 0.6859\n",
            "FOLD 4 TESTING\n",
            "FOLD 4 Test Accuracy: 0.4\n",
            "FOLD 4 Confusion Matrix: [[3 7]\n",
            " [5 5]]\n",
            "FOLD 4 AREA UNDER ROC CURVE: 0.4\n",
            "FOLD 4 AREA UNDER P-R CURVE: 0.5833333333333334\n",
            "FOLD 5\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6940, Accuracy: 0.4929\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6920, Accuracy: 0.5235\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6902, Accuracy: 0.5519\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6885, Accuracy: 0.5818\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6869, Accuracy: 0.6017\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6854, Accuracy: 0.6216\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6839, Accuracy: 0.6401\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6824, Accuracy: 0.6465\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6809, Accuracy: 0.6515\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6795, Accuracy: 0.6629\n",
            "OVERALL LOSS EPOCH: 0.6864\n",
            "FOLD 5 TESTING\n",
            "FOLD 5 Test Accuracy: 0.5\n",
            "FOLD 5 Confusion Matrix: [[6 1]\n",
            " [6 1]]\n",
            "FOLD 5 AREA UNDER ROC CURVE: 0.5\n",
            "FOLD 5 AREA UNDER P-R CURVE: 0.5357142857142857\n",
            "FOLD 6\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6943, Accuracy: 0.4862\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6924, Accuracy: 0.5108\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6908, Accuracy: 0.5333\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6893, Accuracy: 0.5482\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6878, Accuracy: 0.5744\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6864, Accuracy: 0.5871\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6851, Accuracy: 0.6013\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6837, Accuracy: 0.6163\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6824, Accuracy: 0.6275\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6811, Accuracy: 0.6402\n",
            "OVERALL LOSS EPOCH: 0.6873\n",
            "FOLD 6 TESTING\n",
            "FOLD 6 Test Accuracy: 0.5\n",
            "FOLD 6 Confusion Matrix: [[7 4]\n",
            " [7 4]]\n",
            "FOLD 6 AREA UNDER ROC CURVE: 0.5\n",
            "FOLD 6 AREA UNDER P-R CURVE: 0.5909090909090908\n",
            "FOLD 7\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6941, Accuracy: 0.4966\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6922, Accuracy: 0.5237\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6907, Accuracy: 0.5485\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6893, Accuracy: 0.5755\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6879, Accuracy: 0.5875\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6866, Accuracy: 0.6011\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6853, Accuracy: 0.6086\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6841, Accuracy: 0.6153\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6829, Accuracy: 0.6236\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6817, Accuracy: 0.6266\n",
            "OVERALL LOSS EPOCH: 0.6875\n",
            "FOLD 7 TESTING\n",
            "FOLD 7 Test Accuracy: 0.5\n",
            "FOLD 7 Confusion Matrix: [[8 8]\n",
            " [8 8]]\n",
            "FOLD 7 AREA UNDER ROC CURVE: 0.5\n",
            "FOLD 7 AREA UNDER P-R CURVE: 0.625\n",
            "FOLD 8\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6938, Accuracy: 0.5038\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6920, Accuracy: 0.5324\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6905, Accuracy: 0.5535\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6890, Accuracy: 0.5738\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6876, Accuracy: 0.5858\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6863, Accuracy: 0.5994\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6850, Accuracy: 0.6114\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6837, Accuracy: 0.6212\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6825, Accuracy: 0.6340\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6813, Accuracy: 0.6431\n",
            "OVERALL LOSS EPOCH: 0.6872\n",
            "FOLD 8 TESTING\n",
            "FOLD 8 Test Accuracy: 0.5\n",
            "FOLD 8 Confusion Matrix: [[13  2]\n",
            " [13  2]]\n",
            "FOLD 8 AREA UNDER ROC CURVE: 0.5\n",
            "FOLD 8 AREA UNDER P-R CURVE: 0.5333333333333333\n",
            "FOLD 9\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6944, Accuracy: 0.4798\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6923, Accuracy: 0.5173\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6906, Accuracy: 0.5393\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6890, Accuracy: 0.5621\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6875, Accuracy: 0.5878\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6860, Accuracy: 0.5996\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6846, Accuracy: 0.6098\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6833, Accuracy: 0.6135\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6819, Accuracy: 0.6238\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6806, Accuracy: 0.6282\n",
            "OVERALL LOSS EPOCH: 0.6870\n",
            "FOLD 9 TESTING\n",
            "FOLD 9 Test Accuracy: 0.55\n",
            "FOLD 9 Confusion Matrix: [[7 3]\n",
            " [6 4]]\n",
            "FOLD 9 AREA UNDER ROC CURVE: 0.5499999999999999\n",
            "FOLD 9 AREA UNDER P-R CURVE: 0.6357142857142857\n",
            "FOLD 10\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6944, Accuracy: 0.4814\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6924, Accuracy: 0.5149\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6906, Accuracy: 0.5454\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6889, Accuracy: 0.5670\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6873, Accuracy: 0.5878\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6857, Accuracy: 0.6034\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6842, Accuracy: 0.6153\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6828, Accuracy: 0.6243\n",
            "Starting Epoch 8\n",
            "Epoch: 008, Loss: 0.6814, Accuracy: 0.6332\n",
            "Starting Epoch 9\n",
            "Epoch: 009, Loss: 0.6800, Accuracy: 0.6421\n",
            "OVERALL LOSS EPOCH: 0.6868\n",
            "FOLD 10 TESTING\n",
            "FOLD 10 Test Accuracy: 0.5789473684210527\n",
            "FOLD 10 Confusion Matrix: [[16  3]\n",
            " [13  6]]\n",
            "FOLD 10 AREA UNDER ROC CURVE: 0.5789473684210527\n",
            "FOLD 10 AREA UNDER P-R CURVE: 0.6622807017543859\n",
            "10 FOLD CROSS VALIDATION RESULT\n",
            "--------------------------------------------------------------\n",
            "Average Training Accuracy 0.5861357770207773\n",
            "Average Testing Accuracy 0.5067836257309942\n",
            "True Negative: 76 False Positive: 36 False Negative: 74 True Positive: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GAT**"
      ],
      "metadata": {
        "id": "3t6LX7bstQIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAT (EINZELN)"
      ],
      "metadata": {
        "id": "8OGPjd0rXArV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_accuracy_train = []\n",
        "total_accuracy_train_final = []\n",
        "total_accuracy_test_final = []\n",
        "tn_total = []\n",
        "fp_total = []\n",
        "fn_total = []\n",
        "tp_total = []\n",
        "tprs = []\n",
        "aucs = []\n",
        "w = 1\n",
        "mean_fpr = np.linspace(0,1,100)\n",
        "for test_indel in range(1,11): ################## ten fold cross validation\n",
        "    print(\"FOLD\", test_indel)\n",
        "    print(\"----------------------------------------------------------\")\n",
        "    X_data_train = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_train_X_data_array.npy')\n",
        "    Y_data_train = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_train_Y_data_array.npy')\n",
        "    gene_pair_index_train = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_train_gene_pair_list_array.npy')\n",
        "    count_setx_train = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_train_gene_pair_index_array.npy')\n",
        "    X_data_test = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_test_X_data_array.npy')\n",
        "    Y_data_test = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_test_Y_data_array.npy')\n",
        "    gene_pair_index_test = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_test_gene_pair_list_array.npy')\n",
        "    count_set = np.load('drive/MyDrive/rand_1_10fold_log1p/'+str(test_indel)+'_test_gene_pair_index_array.npy')\n",
        "    trainX_index = [i for i in range(Y_data_train.shape[0])]\n",
        "    validation_index = trainX_index[:int(np.ceil(0.2*len(trainX_index)))]\n",
        "    train_index = trainX_index[int(np.ceil(0.2*len(trainX_index))):]\n",
        "    X_train, y_train = X_data_train[train_index],Y_data_train[train_index][:,np.newaxis]\n",
        "    X_val, y_val= X_data_train[validation_index],Y_data_train[validation_index][:,np.newaxis]\n",
        "    X_test, y_test= X_data_test,Y_data_test[:,np.newaxis]\n",
        "\n",
        "    # X_train, y_train, X_val, y_val, X_test, y_test, adj = mnist.load_data()\n",
        "    # X_train, X_val, X_test = X_train[..., None], X_val[..., None], X_test[..., None]\n",
        "    N = X_train.shape[-2]  # Number of nodes in the graphs\n",
        "    F = X_train.shape[-1]  # Node features dimensionality\n",
        "    n_out = y_train.shape[-1]  # Dimension of the target\n",
        "\n",
        "    ############################################\n",
        "    #for further training without validation\n",
        "\n",
        "    X_train = np.append(X_train,X_val,axis=0)\n",
        "\n",
        "    y_train = np.append(y_train,y_val,axis=0)\n",
        "    ############################################\n",
        "\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "    X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "    y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "    #dataset = data_utils.TensorDataset(X_train, y_train)\n",
        "\n",
        "    #train_loader = data_utils.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # for GAT because static graph not supported\n",
        "    #print(edge_index)\n",
        "    #adj_result = [edge_index] *1417\n",
        "    #stacked_tensor = torch.stack(adj_result, dim=0)\n",
        "\n",
        "\n",
        "    #te = [Data(x_train=x, edge_index=a, y_train = y) for x,a,y in zip(X_train, adj_result, y_train)]\n",
        "    #print(te)\n",
        "    #batch = Batch.from_data_list(te)\n",
        "    #batch = batch.to(device)\n",
        "\n",
        "    #train_loader = data_utils.DataLoader(t, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    #test_loader = data_utils.DataLoader(X_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = GCN().to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
        "\n",
        "    all_losses = []\n",
        "\n",
        "    #Initialize Variables for EarlyStopping\n",
        "    best_loss = float('inf')\n",
        "    best_model_weights = None\n",
        "    patience = 5\n",
        "    t = open('training/'+str(test_indel)+'results.txt', 'w')\n",
        "\n",
        "    epochs = 8\n",
        "    for epoch in range(8):\n",
        "      print(\"Starting Epoch\", epoch)\n",
        "      accuracy_train_list = []\n",
        "      out_list = []\n",
        "      loss_list = []\n",
        "      model.train()\n",
        "      for i, data in enumerate(X_train):  # Iterate over the training dataset.\n",
        "        # for GAT because static graph not supported\n",
        "        optimizer.zero_grad()  # Clear gradients.\n",
        "        out = model(data.to(device), edge_index.to(device)) # Perform a single forward pass.\n",
        "        out_list.append(out)\n",
        "\n",
        "        loss = criterion(out, y_train[i].to(device)) # Compute the loss.\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        loss.backward() # Derive gradients.\n",
        "        optimizer.step() # Update parameters based on gradients.\n",
        "\n",
        "      total_loss = sum(loss_list) / len(loss_list)\n",
        "      output = out_list\n",
        "\n",
        "\n",
        "      # training accuracy, threshold 0.5\n",
        "      final_out = []\n",
        "      for out in output:\n",
        "        output_train_acc = out\n",
        "        output_train_acc[output_train_acc >= 0.5] = 1\n",
        "        output_train_acc[output_train_acc < 0.5] = 0\n",
        "        output_train_acc_int = output_train_acc.tolist()\n",
        "        output_train_acc_int = [int(x) for x in output_train_acc_int]\n",
        "        #output_train_acc_int = flatten_concatenation(output_train_acc_int)\n",
        "        #print(output_train_acc_int)\n",
        "        #output_train_acc_int = [ int(x) for x in output_train_acc_int ]\n",
        "        final_out.append(output_train_acc_int)\n",
        "\n",
        "      final_output = flatten_concatenation(final_out)\n",
        "\n",
        "\n",
        "      all_losses.append(total_loss)\n",
        "\n",
        "      accuracy_train = accuracy_score(y_train.flatten(), final_output)\n",
        "      total_accuracy_train.append(accuracy_train)\n",
        "      print(f'Epoch: {epoch:03d}, Loss: {total_loss:.4f}, Accuracy: {accuracy_train:.4f}')\n",
        "\n",
        "      t.write(\"FOLD\" + '\\t' + str(test_indel) + '\\t' + \"EPOCH\" + '\\t' + str(epoch) +\"LOSS\" + \"\\t\"+str(total_loss) + \"\\t\"+ '\\t' + \"TRAINING ACCURACY\" + '\\t'+ str(accuracy_train) + '\\n')\n",
        "\n",
        "\n",
        "\n",
        "    t.close()\n",
        "\n",
        "    overall_loss = sum(all_losses) / epochs\n",
        "    print(f'OVERALL LOSS EPOCH: {overall_loss:.4f}')\n",
        "    sum_train_acc = sum(total_accuracy_train) / epochs\n",
        "    total_accuracy_train = []\n",
        "    total_accuracy_train_final.append(sum_train_acc)\n",
        "\n",
        "    # Load the best model weights\n",
        "    #model.load_state_dict(best_model_weights)\n",
        "\n",
        "    #############################################\n",
        "    #              TEST                         #\n",
        "    #############################################\n",
        "\n",
        "    print(\"FOLD\", test_indel, \"TESTING\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    out_list = []\n",
        "    for data in X_test:  # Iterate  over the test dataset.\n",
        "        out = model(data.to(device), edge_index.to(device))\n",
        "        out_list.append(out)\n",
        "\n",
        "    test_output = out_list\n",
        "    final_out = []\n",
        "    for out in test_output:\n",
        "      output_test_acc = out\n",
        "      output_test_acc[output_test_acc >= 0.5] = 1\n",
        "      output_test_acc[output_test_acc < 0.5] = 0\n",
        "      #output_train_acc_int = int(output_train_acc)   # float to int\n",
        "      output_test_acc_int = output_test_acc.tolist()\n",
        "      #output_test_acc_int = flatten_concatenation(output_test_acc_int)\n",
        "      output_test_acc_int = [ int(x) for x in output_test_acc_int ]\n",
        "      final_out.append(output_test_acc_int)\n",
        "\n",
        "    final_output = flatten_concatenation(final_out)\n",
        "    #final_output = final_output.to(torch.device(\"cpu\"))\n",
        "\n",
        "\n",
        "    #Accuracy\n",
        "    accuracy_test = accuracy_score(y_test.flatten(), final_output)\n",
        "    total_accuracy_test_final.append(accuracy_test)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test.flatten(), final_output)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    tn_total.append(tn)\n",
        "    fp_total.append(fp)\n",
        "    fn_total.append(fn)\n",
        "    tp_total.append(tp)\n",
        "\n",
        "\n",
        "    y_testy = y_test.flatten()\n",
        "    y_predicty = final_output\n",
        "    s = open('result/'+str(test_indel)+'divided_interaction.txt', 'w')\n",
        "    for jj in range(len(count_set) - 1):  # len(count_set)-1):\n",
        "        if count_set[jj] < count_set[jj + 1]:\n",
        "            y_test_1 = y_testy[count_set[jj]:count_set[jj + 1]]\n",
        "            y_predict = y_predicty[count_set[jj]:count_set[jj + 1]]\n",
        "            # Score trained model.\n",
        "            cm_1 = confusion_matrix(y_test_1, y_predict)\n",
        "            tn_1, fp_1, fn_1, tp_1 = cm_1.ravel()\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(y_test_1, y_predict, pos_label=1)\n",
        "            auc = metrics.auc(fpr, tpr)\n",
        "            li_name = ligand_name(gene_pair_index_test[count_set[jj]])\n",
        "            s.write(li_name + '\\n')\n",
        "            s.write(str(jj) + '\\t' + str(count_set[jj]) + '\\t' + str(count_set[jj + 1]) + '\\t' + str(auc) + '\\n')\n",
        "            s.write(str(jj) + '\\t' + str(count_set[jj]) + '\\t' + str(count_set[jj + 1]) + '\\t' + \"TN\" + str(tn_1) + \"FP\" + str(fp_1) + \"FN\" + str(fn_1) + \"TP\"+ str(tp_1) + '\\n')\n",
        "\n",
        "    s.close()\n",
        "\n",
        "    print(\"FOLD\", test_indel, \"Test Accuracy:\", accuracy_test)\n",
        "    print(\"FOLD\", test_indel,\"Confusion Matrix:\", cm)\n",
        "\n",
        "    fpr, tpr, t = roc_curve(y_test.flatten(), final_output)\n",
        "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    aucs.append(roc_auc)\n",
        "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (w, roc_auc))\n",
        "    w = w+1\n",
        "\n",
        "\n",
        "    precision1, recall1, thresholds1 = precision_recall_curve(y_test.flatten(), final_output)\n",
        "    auc_score_rp = metrics.auc(recall1, precision1)\n",
        "    print(\"FOLD\", test_indel,\"AREA UNDER ROC CURVE:\", roc_auc)\n",
        "    print(\"FOLD\", test_indel,\"AREA UNDER P-R CURVE:\", auc_score_rp)\n",
        "    e = open('ending/'+str(test_indel)+'curves.txt', 'w')\n",
        "    e.write(\"FOLD\" + \"\\t\"+  str(test_indel)+ \"\\t\"+ \"TEST ACCURACY:\" + \"\\t\"+ str(accuracy_test) + '\\n')\n",
        "    e.write(\"FOLD\" + \"\\t\"+  str(test_indel)+ \"\\t\"+ \"TEST CONFUSION MATRIX:\" + \"\\t\"+ str(cm) + '\\n')\n",
        "    e.write(\"FOLD\" + \"\\t\"+  str(test_indel)+ \"\\t\"+ \"AREA UNDER ROC CURVE:\" + \"\\t\"+ str(roc_auc) + '\\n')\n",
        "    e.write(\"FOLD\" + \"\\t\"+  str(test_indel)+ \"\\t\"+ \"AREA UNDER P-R CURVE:\" + \"\\t\"+ str(auc_score_rp) + '\\n')\n",
        "    e.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"10 FOLD CROSS VALIDATION RESULT\")\n",
        "print(\"--------------------------------------------------------------\")\n",
        "avg_accuracy_train = sum(total_accuracy_train_final) / 10\n",
        "avg_accuracy_test = sum(total_accuracy_test_final) / 10\n",
        "print(\"Average Training Accuracy\", avg_accuracy_train)\n",
        "print(\"Average Testing Accuracy\", avg_accuracy_test)\n",
        "print(\"True Negative:\", sum(tn_total), \"False Positive:\", sum(fp_total), \"False Negative:\", sum(fn_total), \"True Positive:\", sum(tp_total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5_T1YBIXC0O",
        "outputId": "fa2ed660-f972-41a1-a3bf-2e8b605ec791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 1\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6916, Accuracy: 0.5655\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6879, Accuracy: 0.5897\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6849, Accuracy: 0.5903\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6822, Accuracy: 0.6134\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6796, Accuracy: 0.6281\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6771, Accuracy: 0.6462\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6748, Accuracy: 0.6659\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6725, Accuracy: 0.6772\n",
            "OVERALL LOSS EPOCH: 0.6813\n",
            "FOLD 1 TESTING\n",
            "FOLD 1 Test Accuracy: 0.6\n",
            "FOLD 1 Confusion Matrix: [[3 2]\n",
            " [2 3]]\n",
            "FOLD 1 AREA UNDER ROC CURVE: 0.6\n",
            "FOLD 1 AREA UNDER P-R CURVE: 0.7\n",
            "FOLD 2\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6918, Accuracy: 0.5453\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6881, Accuracy: 0.6144\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6850, Accuracy: 0.6376\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6822, Accuracy: 0.6585\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6796, Accuracy: 0.6748\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6771, Accuracy: 0.6847\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6748, Accuracy: 0.6812\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6725, Accuracy: 0.6893\n",
            "OVERALL LOSS EPOCH: 0.6814\n",
            "FOLD 2 TESTING\n",
            "FOLD 2 Test Accuracy: 0.65\n",
            "FOLD 2 Confusion Matrix: [[6 4]\n",
            " [3 7]]\n",
            "FOLD 2 AREA UNDER ROC CURVE: 0.65\n",
            "FOLD 2 AREA UNDER P-R CURVE: 0.7431818181818182\n",
            "FOLD 3\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6914, Accuracy: 0.5490\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6870, Accuracy: 0.5770\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6835, Accuracy: 0.5815\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6804, Accuracy: 0.6038\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6775, Accuracy: 0.6174\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6747, Accuracy: 0.6317\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6720, Accuracy: 0.6494\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6694, Accuracy: 0.6499\n",
            "OVERALL LOSS EPOCH: 0.6795\n",
            "FOLD 3 TESTING\n",
            "FOLD 3 Test Accuracy: 0.3888888888888889\n",
            "FOLD 3 Confusion Matrix: [[4 5]\n",
            " [6 3]]\n",
            "FOLD 3 AREA UNDER ROC CURVE: 0.38888888888888884\n",
            "FOLD 3 AREA UNDER P-R CURVE: 0.5208333333333334\n",
            "FOLD 4\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6914, Accuracy: 0.5484\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6873, Accuracy: 0.6290\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6836, Accuracy: 0.6434\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6803, Accuracy: 0.6567\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6771, Accuracy: 0.6676\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6742, Accuracy: 0.6780\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6714, Accuracy: 0.6838\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6688, Accuracy: 0.6878\n",
            "OVERALL LOSS EPOCH: 0.6793\n",
            "FOLD 4 TESTING\n",
            "FOLD 4 Test Accuracy: 0.4\n",
            "FOLD 4 Confusion Matrix: [[3 7]\n",
            " [5 5]]\n",
            "FOLD 4 AREA UNDER ROC CURVE: 0.4\n",
            "FOLD 4 AREA UNDER P-R CURVE: 0.5833333333333334\n",
            "FOLD 5\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6916, Accuracy: 0.5478\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6879, Accuracy: 0.6052\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6847, Accuracy: 0.6246\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6818, Accuracy: 0.6439\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6790, Accuracy: 0.6655\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6764, Accuracy: 0.6724\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6738, Accuracy: 0.6797\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6714, Accuracy: 0.6809\n",
            "OVERALL LOSS EPOCH: 0.6808\n",
            "FOLD 5 TESTING\n",
            "FOLD 5 Test Accuracy: 0.5\n",
            "FOLD 5 Confusion Matrix: [[6 1]\n",
            " [6 1]]\n",
            "FOLD 5 AREA UNDER ROC CURVE: 0.5\n",
            "FOLD 5 AREA UNDER P-R CURVE: 0.5357142857142857\n",
            "FOLD 6\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6918, Accuracy: 0.5395\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6880, Accuracy: 0.6388\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6848, Accuracy: 0.6501\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6818, Accuracy: 0.6633\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6789, Accuracy: 0.6740\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6762, Accuracy: 0.6776\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6736, Accuracy: 0.6812\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6711, Accuracy: 0.6770\n",
            "OVERALL LOSS EPOCH: 0.6808\n",
            "FOLD 6 TESTING\n",
            "FOLD 6 Test Accuracy: 0.45454545454545453\n",
            "FOLD 6 Confusion Matrix: [[6 5]\n",
            " [7 4]]\n",
            "FOLD 6 AREA UNDER ROC CURVE: 0.45454545454545453\n",
            "FOLD 6 AREA UNDER P-R CURVE: 0.5631313131313131\n",
            "FOLD 7\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6922, Accuracy: 0.5343\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6894, Accuracy: 0.6046\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6872, Accuracy: 0.6004\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6853, Accuracy: 0.6118\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6835, Accuracy: 0.6316\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6817, Accuracy: 0.6394\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6800, Accuracy: 0.6448\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6783, Accuracy: 0.6593\n",
            "OVERALL LOSS EPOCH: 0.6847\n",
            "FOLD 7 TESTING\n",
            "FOLD 7 Test Accuracy: 0.59375\n",
            "FOLD 7 Confusion Matrix: [[ 9  7]\n",
            " [ 6 10]]\n",
            "FOLD 7 AREA UNDER ROC CURVE: 0.59375\n",
            "FOLD 7 AREA UNDER P-R CURVE: 0.7003676470588236\n",
            "FOLD 8\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6924, Accuracy: 0.5404\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6896, Accuracy: 0.5904\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6872, Accuracy: 0.6169\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6850, Accuracy: 0.6349\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6830, Accuracy: 0.6584\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6810, Accuracy: 0.6693\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6791, Accuracy: 0.6795\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6772, Accuracy: 0.6819\n",
            "OVERALL LOSS EPOCH: 0.6843\n",
            "FOLD 8 TESTING\n",
            "FOLD 8 Test Accuracy: 0.6333333333333333\n",
            "FOLD 8 Confusion Matrix: [[11  4]\n",
            " [ 7  8]]\n",
            "FOLD 8 AREA UNDER ROC CURVE: 0.6333333333333333\n",
            "FOLD 8 AREA UNDER P-R CURVE: 0.7166666666666666\n",
            "FOLD 9\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6917, Accuracy: 0.5494\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6877, Accuracy: 0.6269\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6842, Accuracy: 0.6404\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6810, Accuracy: 0.6545\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6781, Accuracy: 0.6592\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6753, Accuracy: 0.6698\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6727, Accuracy: 0.6763\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6702, Accuracy: 0.6810\n",
            "OVERALL LOSS EPOCH: 0.6801\n",
            "FOLD 9 TESTING\n",
            "FOLD 9 Test Accuracy: 0.6\n",
            "FOLD 9 Confusion Matrix: [[7 3]\n",
            " [5 5]]\n",
            "FOLD 9 AREA UNDER ROC CURVE: 0.5999999999999999\n",
            "FOLD 9 AREA UNDER P-R CURVE: 0.6875\n",
            "FOLD 10\n",
            "----------------------------------------------------------\n",
            "Starting Epoch 0\n",
            "Epoch: 000, Loss: 0.6921, Accuracy: 0.5494\n",
            "Starting Epoch 1\n",
            "Epoch: 001, Loss: 0.6887, Accuracy: 0.5988\n",
            "Starting Epoch 2\n",
            "Epoch: 002, Loss: 0.6859, Accuracy: 0.6119\n",
            "Starting Epoch 3\n",
            "Epoch: 003, Loss: 0.6834, Accuracy: 0.6357\n",
            "Starting Epoch 4\n",
            "Epoch: 004, Loss: 0.6810, Accuracy: 0.6458\n",
            "Starting Epoch 5\n",
            "Epoch: 005, Loss: 0.6787, Accuracy: 0.6512\n",
            "Starting Epoch 6\n",
            "Epoch: 006, Loss: 0.6765, Accuracy: 0.6625\n",
            "Starting Epoch 7\n",
            "Epoch: 007, Loss: 0.6743, Accuracy: 0.6690\n",
            "OVERALL LOSS EPOCH: 0.6826\n",
            "FOLD 10 TESTING\n",
            "FOLD 10 Test Accuracy: 0.631578947368421\n",
            "FOLD 10 Confusion Matrix: [[12  7]\n",
            " [ 7 12]]\n",
            "FOLD 10 AREA UNDER ROC CURVE: 0.631578947368421\n",
            "FOLD 10 AREA UNDER P-R CURVE: 0.7236842105263157\n",
            "10 FOLD CROSS VALIDATION RESULT\n",
            "--------------------------------------------------------------\n",
            "Average Training Accuracy 0.6339723853765147\n",
            "Average Testing Accuracy 0.5452096624136098\n",
            "True Negative: 67 False Positive: 45 False Negative: 54 True Positive: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTIZEN**"
      ],
      "metadata": {
        "id": "70L5VPrloCX_"
      }
    }
  ]
}